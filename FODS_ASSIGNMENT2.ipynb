{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FODS_ASSIGNMENT2 (3).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA4e1IUQWLrc"
      },
      "source": [
        "Importing Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-nov0aS98pi"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_cbE1uOWkdl"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kci1vVII-o5b",
        "outputId": "8131dc4c-5d0e-40d7-8916-ecb2175b88ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdRx1rgxWmfY"
      },
      "source": [
        "Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqI8nnak-pvN"
      },
      "source": [
        "def cost_function(X,y,w):\n",
        "  hypothesis = np.dot(X,w.T)\n",
        "  J = (1/(2*len(y))) * np.sum((hypothesis - y)**2)\n",
        "  return J"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbcKZqn5lszO"
      },
      "source": [
        "def batch_gradient_descent(X,y,w,alpha,iters):\n",
        "  cost_history = np.zeros(iters)\n",
        "  for i in range(iters):\n",
        "    hypothesis = np.dot(X,w.T)\n",
        "    w = w - (alpha/len(y)) * np.dot(hypothesis - y,X)\n",
        "    cost_history[i] = cost_function(X,y,w)\n",
        "  return w,cost_history"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC521H8rltmr"
      },
      "source": [
        "def Normalise(X):\n",
        "  mean = X.mean()\n",
        "  std = np.std(X,axis=0)\n",
        "  m = len(X)\n",
        "  X_norm = (X-mean)/std\n",
        "  return X_norm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veYyxSjKlxv5"
      },
      "source": [
        "def root_mean_squared_error(y_hat,y):\n",
        "  error = (1/len(y)) * np.sum((y_hat - y)**2)\n",
        "  rmse = np.sqrt(error)\n",
        "  return rmse"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb3gNUJ3Wptg"
      },
      "source": [
        "Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG773QPdl5xu"
      },
      "source": [
        "from random import Random\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/FoDS-Assignment-2.csv\")\n",
        "Random(14).shuffle(data.values)\n",
        "X = data.drop(\"price\",axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwy4ct0loCrp"
      },
      "source": [
        "mean=X.mean()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF9vSmn5qlTu",
        "outputId": "7eb0dffd-a494-4a2e-d813-8b85857e65fb"
      },
      "source": [
        "mean"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bedrooms             3.382997\n",
              "bathrooms            2.143098\n",
              "sqft_living       2124.656729\n",
              "sqft_lot         15797.568182\n",
              "floors               1.509787\n",
              "waterfront           0.003367\n",
              "view                 0.245791\n",
              "condition            3.425926\n",
              "grade                7.687710\n",
              "sqft_above        1815.946337\n",
              "sqft_basement      304.373737\n",
              "sqft_living15     2019.319865\n",
              "sqft_lot15       12889.924242\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIN8W9kplhI0",
        "outputId": "44294326-efa7-4ece-9be8-12932f041bd1"
      },
      "source": [
        "data['floors'][100]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZOcXrbQp9g2"
      },
      "source": [
        "List = [\"bedrooms\",\t\"bathrooms\",\t\"sqft_living\",\t\"sqft_lot\",\t\"floors\",\t\"waterfront\",\t\"view\",\t\"condition\",\t\"grade\",\t\"sqft_above\",\t\"sqft_basement\",\t\"sqft_living15\",\t\"sqft_lot15\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrlaTIzinTUN",
        "outputId": "65974bd3-1fcb-4841-b294-ecd9a3db38bd"
      },
      "source": [
        "# missing values\n",
        "for j in List:\n",
        "  for i in range(1188):\n",
        "    if pd.isnull(data[j][i]):\n",
        "      data[j][i]=mean[j]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5ROi7IMn8if",
        "outputId": "0d10a765-fe7f-4c4f-8f56-5d0e5ee95606"
      },
      "source": [
        "data['floors'][100]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.509787234042553"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AG_1CJMWu8B"
      },
      "source": [
        "Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1cWczu6qeO1"
      },
      "source": [
        "X = data.drop(\"price\",axis=1)\n",
        "y = data[\"price\"]\n",
        "m = len(X)\n",
        "X_train = X[:int(m*0.7)]\n",
        "X_test = X[int(m*0.7):]\n",
        "y_train = y[:int(m*0.7)]\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y[int(m*0.7):]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoRvKktGTzlN"
      },
      "source": [
        "X_rand_tr = Normalise(X_train)\n",
        "X_rand_tr = X_rand_tr.to_numpy()\n",
        "X_rand_train = np.c_[np.ones((831)),X_rand_tr]\n",
        "X_rand_te = Normalise(X_test)\n",
        "X_rand_te = X_rand_te.to_numpy()\n",
        "X_rand_test = np.c_[np.ones((357)),X_rand_te]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvyJAPyWWyhG"
      },
      "source": [
        "Greedy Forward Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3dCQUG2q9M9",
        "outputId": "620a8362-ab57-4e3d-e646-a3775e8abea6"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_new]\n",
        "  w = np.zeros((2))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "503141.2176333068\n",
            "290705.9684090345\n",
            "Epoch 1\n",
            "444245.34843055176\n",
            "263557.4563054164\n",
            "Epoch 2\n",
            "381370.7371767867\n",
            "223686.8512829784\n",
            "Epoch 3\n",
            "521293.9244502362\n",
            "308808.6607574667\n",
            "Epoch 4\n",
            "505712.8357636968\n",
            "296327.53332557227\n",
            "Epoch 5\n",
            "511974.89598917495\n",
            "306078.7397143195\n",
            "Epoch 6\n",
            "501634.6450604561\n",
            "283195.10075743106\n",
            "Epoch 7\n",
            "522104.53465725953\n",
            "309095.6954302271\n",
            "Epoch 8\n",
            "408232.73581020837\n",
            "235156.78605280962\n",
            "Epoch 9\n",
            "417629.63931158656\n",
            "250285.755647223\n",
            "Epoch 10\n",
            "492443.4937822303\n",
            "297970.7313769803\n",
            "Epoch 11\n",
            "442840.92842264514\n",
            "250977.08011604907\n",
            "Epoch 12\n",
            "521436.087201763\n",
            "308627.39623572497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvAs2oCoXrTv"
      },
      "source": [
        "Feature 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO35Qov5khoK",
        "outputId": "6274fe09-f957-4ba6-887a-ac294f5700ed"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_norm[:,2],X_new]\n",
        "  w = np.zeros((3))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,2],X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "376458.4295389496\n",
            "222698.40313841775\n",
            "Epoch 1\n",
            "381399.2747294826\n",
            "223682.5369034382\n",
            "Epoch 2\n",
            "381370.7371767863\n",
            "223686.8512829784\n",
            "Epoch 3\n",
            "381383.6104112228\n",
            "223685.6631717668\n",
            "Epoch 4\n",
            "381848.01918075426\n",
            "223306.5867031213\n",
            "Epoch 5\n",
            "376347.15396267135\n",
            "221936.74169221194\n",
            "Epoch 6\n",
            "377937.8161766611\n",
            "211832.06550047034\n",
            "Epoch 7\n",
            "380794.8264937681\n",
            "222978.48659880104\n",
            "Epoch 8\n",
            "373537.8830258457\n",
            "215883.48053015347\n",
            "Epoch 9\n",
            "381124.91823985137\n",
            "223611.8645343454\n",
            "Epoch 10\n",
            "381070.44453494553\n",
            "223667.49584153958\n",
            "Epoch 11\n",
            "382904.2839576545\n",
            "221277.32037998337\n",
            "Epoch 12\n",
            "380386.0428712074\n",
            "223187.50094680776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7QO_bOtYPdJ"
      },
      "source": [
        "Feature 3 and 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jItTxXJYBi8",
        "outputId": "4ee3c9df-1e2d-448c-c02d-aeb1110e1772"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_norm[:,8],X_norm[:,2],X_new]\n",
        "  w = np.zeros((4))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,8],X_test_norm[:,2],X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "371039.16347164294\n",
            "215609.55253038352\n",
            "Epoch 1\n",
            "373157.0927111163\n",
            "215349.36551013263\n",
            "Epoch 2\n",
            "373537.88302584493\n",
            "215883.48053015347\n",
            "Epoch 3\n",
            "373590.7320526675\n",
            "215857.70586896202\n",
            "Epoch 4\n",
            "372941.5179890011\n",
            "215769.3653962037\n",
            "Epoch 5\n",
            "367521.09843689227\n",
            "213599.72741573423\n",
            "Epoch 6\n",
            "370748.3673890154\n",
            "203900.76480749587\n",
            "Epoch 7\n",
            "371842.3241564217\n",
            "213406.16508680527\n",
            "Epoch 8\n",
            "373537.88302584575\n",
            "215883.48053015347\n",
            "Epoch 9\n",
            "373538.6175381022\n",
            "215611.88954747395\n",
            "Epoch 10\n",
            "370662.5444298159\n",
            "215065.4834827488\n",
            "Epoch 11\n",
            "375073.9160613381\n",
            "215380.43378061088\n",
            "Epoch 12\n",
            "372852.4883594311\n",
            "215417.28885350353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2blJ28udkSw"
      },
      "source": [
        "Feature 3,6 and 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNPE5N-qYdCY",
        "outputId": "3ef2651a-7a3a-411b-e4ae-dc4bf3b184b3"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_norm[:,5],X_norm[:,2],X_norm[:,8],X_new]\n",
        "  w = np.zeros((5))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,5],X_test_norm[:,2],X_test_norm[:,8],X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "366081.34618936956\n",
            "213478.35673191946\n",
            "Epoch 1\n",
            "367500.93409674655\n",
            "213048.38412050912\n",
            "Epoch 2\n",
            "367521.0984368916\n",
            "213599.72741573423\n",
            "Epoch 3\n",
            "367567.5208041791\n",
            "213569.91000031296\n",
            "Epoch 4\n",
            "366850.0868650228\n",
            "213471.7909704976\n",
            "Epoch 5\n",
            "367521.09843689227\n",
            "213599.72741573423\n",
            "Epoch 6\n",
            "368414.4761982729\n",
            "203567.7787744034\n",
            "Epoch 7\n",
            "365617.06349593145\n",
            "211010.10607270134\n",
            "Epoch 8\n",
            "367521.0984368923\n",
            "213599.72741573423\n",
            "Epoch 9\n",
            "367592.2385289237\n",
            "213322.32818300757\n",
            "Epoch 10\n",
            "364873.8049596437\n",
            "212794.86519071614\n",
            "Epoch 11\n",
            "369011.34793785017\n",
            "212969.81858465425\n",
            "Epoch 12\n",
            "366912.7510607854\n",
            "213155.80834782642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-OCQYA9ZCS8"
      },
      "source": [
        "Feature 3,6,9,11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc6y1sULYrQd",
        "outputId": "c94ca6a8-40b3-46dc-b265-54939c3c3f69"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_norm[:,2],X_norm[:,5],X_norm[:,8],X_norm[:,10],X_new]\n",
        "  w = np.zeros((6))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,2],X_test_norm[:,5],X_test_norm[:,8],X_test_norm[:,10],X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "362946.99051357165\n",
            "212596.5066419446\n",
            "Epoch 1\n",
            "365000.89302835567\n",
            "212296.80294506735\n",
            "Epoch 2\n",
            "364873.8049596437\n",
            "212794.86519071617\n",
            "Epoch 3\n",
            "364887.33100694214\n",
            "212738.16622051387\n",
            "Epoch 4\n",
            "364942.0550353325\n",
            "212782.82867443064\n",
            "Epoch 5\n",
            "364873.8049596437\n",
            "212794.86519071617\n",
            "Epoch 6\n",
            "367163.0523273051\n",
            "203319.3044985403\n",
            "Epoch 7\n",
            "363925.3549864125\n",
            "210640.9029003226\n",
            "Epoch 8\n",
            "364873.80495964375\n",
            "212794.86519071614\n",
            "Epoch 9\n",
            "360027.0667702455\n",
            "212302.66872632183\n",
            "Epoch 10\n",
            "364873.8049596437\n",
            "212794.86519071614\n",
            "Epoch 11\n",
            "366325.4919921108\n",
            "211893.20882809645\n",
            "Epoch 12\n",
            "364460.2419416528\n",
            "212445.08976827803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMTU9cx9ZoxE"
      },
      "source": [
        "Feature 3,6,9,10,11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKSGsrDcZc17",
        "outputId": "9e9c4579-409e-49cb-ed5e-9a14e266b3d3"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_norm[:,2],X_norm[:,5],X_norm[:,8],X_norm[:,9],X_norm[:,10],X_new]\n",
        "  w = np.zeros((7))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,2],X_test_norm[:,5],X_test_norm[:,8],X_test_norm[:,9],X_test_norm[:,10],X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "357569.3056895571\n",
            "212046.91950266017\n",
            "Epoch 1\n",
            "360193.2607546305\n",
            "211813.65729900755\n",
            "Epoch 2\n",
            "360026.8184578964\n",
            "212302.6687236974\n",
            "Epoch 3\n",
            "360054.7298119018\n",
            "212245.9194626527\n",
            "Epoch 4\n",
            "360105.55941219104\n",
            "212294.25287892623\n",
            "Epoch 5\n",
            "360027.0670752114\n",
            "212302.66872632678\n",
            "Epoch 6\n",
            "361007.02692244586\n",
            "202473.8405587902\n",
            "Epoch 7\n",
            "359483.01633047336\n",
            "210236.8239383081\n",
            "Epoch 8\n",
            "360027.0591324831\n",
            "212302.66872619413\n",
            "Epoch 9\n",
            "360026.748164895\n",
            "212302.6687235631\n",
            "Epoch 10\n",
            "360026.850884292\n",
            "212302.66872387615\n",
            "Epoch 11\n",
            "362326.34968966333\n",
            "211595.9503584405\n",
            "Epoch 12\n",
            "359589.5373412515\n",
            "211951.31365804668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMa0-tjNaM0y"
      },
      "source": [
        "Feature 1,3,6,9,10,11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uw8ceehaDDP",
        "outputId": "e6383df4-19ae-45f9-cb82-658f5c265de9"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_norm[:,0],X_norm[:,2],X_norm[:,5],X_norm[:,8],X_norm[:,9],X_norm[:,10],X_new]\n",
        "  w = np.zeros((8))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,0],X_test_norm[:,2],X_test_norm[:,5],X_test_norm[:,8],X_test_norm[:,9],X_test_norm[:,10],X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "357569.3056367503\n",
            "212046.9195026594\n",
            "Epoch 1\n",
            "358301.65474871977\n",
            "211664.98791791752\n",
            "Epoch 2\n",
            "357569.0621409662\n",
            "212046.91950000467\n",
            "Epoch 3\n",
            "357594.49366521114\n",
            "211988.41616095198\n",
            "Epoch 4\n",
            "357646.3735793353\n",
            "212035.64566734282\n",
            "Epoch 5\n",
            "357569.30598572985\n",
            "212046.9195026651\n",
            "Epoch 6\n",
            "360139.73036763375\n",
            "202443.8075630197\n",
            "Epoch 7\n",
            "356836.0196123118\n",
            "209944.65752204714\n",
            "Epoch 8\n",
            "357569.29845237435\n",
            "212046.91950253682\n",
            "Epoch 9\n",
            "357568.98206602363\n",
            "212046.9194998515\n",
            "Epoch 10\n",
            "357569.08264285466\n",
            "212046.91950014042\n",
            "Epoch 11\n",
            "359970.74237067375\n",
            "211385.01044943332\n",
            "Epoch 12\n",
            "356931.0281970338\n",
            "211656.12256353215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTDuPlHCaiFb"
      },
      "source": [
        "Feature 1,3,6,8,9,10,11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KxnAs0uaZ2a",
        "outputId": "0308ac6b-b5f2-45ed-8af7-0485479a16a2"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_norm[:,0],X_norm[:,2],X_norm[:,5],X_norm[:,7],X_norm[:,8],X_norm[:,9],X_norm[:,10],X_new]\n",
        "  w = np.zeros((9))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,0],X_test_norm[:,2],X_test_norm[:,5],X_test_norm[:,7],X_test_norm[:,8],X_test_norm[:,9],X_test_norm[:,10],X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "356836.01958153665\n",
            "209944.65752204685\n",
            "Epoch 1\n",
            "357646.83319389506\n",
            "209580.57009091854\n",
            "Epoch 2\n",
            "356835.9104686734\n",
            "209944.65752133983\n",
            "Epoch 3\n",
            "356851.7966528078\n",
            "209912.46552547143\n",
            "Epoch 4\n",
            "356978.16713284596\n",
            "209849.34470883376\n",
            "Epoch 5\n",
            "356836.0199511748\n",
            "209944.65752205017\n",
            "Epoch 6\n",
            "359363.94914283615\n",
            "200865.4524934442\n",
            "Epoch 7\n",
            "356836.02136382466\n",
            "209944.6575220633\n",
            "Epoch 8\n",
            "356836.0133117781\n",
            "209944.6575219904\n",
            "Epoch 9\n",
            "356835.8230900813\n",
            "209944.65752124912\n",
            "Epoch 10\n",
            "356835.8679270334\n",
            "209944.6575212542\n",
            "Epoch 11\n",
            "359440.53095611976\n",
            "209234.84196622824\n",
            "Epoch 12\n",
            "356081.4398225572\n",
            "209392.64082501535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8aOq11Ef_uY"
      },
      "source": [
        "Feature 1,3,6,8,9,10,11,13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVYbfdpVe2dW",
        "outputId": "5265f0f4-c4e8-4cd7-c914-d6163765782f"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "for i in range(13):\n",
        "  X_new = X_norm[:,i]\n",
        "  X_new_1 = np.c_[np.ones((831)),X_norm[:,0],X_norm[:,2],X_norm[:,5],X_norm[:,12],X_norm[:,8],X_norm[:,9],X_norm[:,10],X_norm[:,7],X_new]\n",
        "  w = np.zeros((10))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_1,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_norm[:,0],X_test_norm[:,2],X_test_norm[:,5],X_test_norm[:,12],X_test_norm[:,8],X_test_norm[:,9],X_test_norm[:,10],X_test_norm[:,7],X_test_norm[:,i]]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_1,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "356081.4398403593\n",
            "209392.6408250155\n",
            "Epoch 1\n",
            "356986.5319671555\n",
            "208941.71131704372\n",
            "Epoch 2\n",
            "356081.3778350301\n",
            "209392.64082469404\n",
            "Epoch 3\n",
            "356998.6181029042\n",
            "207830.88245893447\n",
            "Epoch 4\n",
            "356201.3139531942\n",
            "209347.0853111077\n",
            "Epoch 5\n",
            "356081.4401379415\n",
            "209392.6408250174\n",
            "Epoch 6\n",
            "358909.26642340346\n",
            "199635.09024867724\n",
            "Epoch 7\n",
            "356081.44175880373\n",
            "209392.64082502818\n",
            "Epoch 8\n",
            "356081.4333413485\n",
            "209392.6408249739\n",
            "Epoch 9\n",
            "356081.28449219273\n",
            "209392.6408246262\n",
            "Epoch 10\n",
            "356081.31001266325\n",
            "209392.64082460187\n",
            "Epoch 11\n",
            "358893.7745480942\n",
            "208518.90356682127\n",
            "Epoch 12\n",
            "356081.44036091806\n",
            "209392.64082501887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEn1TLIZgt-u"
      },
      "source": [
        "Finished Forward Greedy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIijqQZWX-L9"
      },
      "source": [
        "Backward Greedy Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofXAFomKg2QA"
      },
      "source": [
        "# alpha=0.1\n",
        "# iters=40000\n",
        "# X_norm = Normalise(X_train)\n",
        "# X_norm = X_norm.to_numpy()\n",
        "# for i in range(13):\n",
        "#   X_new = X_norm\n",
        "#   X_new_1 =  np.delete(X_new,i,1)\n",
        "#   X_new_2 = np.c_[np.ones((831)),X_new_1]\n",
        "#   w = np.zeros((13))\n",
        "#   batch_w, J_his_batch = batch_gradient_descent(X_new_2,y_train,w,alpha,iters)\n",
        "#   # plt.plot(range(iters),J_his_batch)\n",
        "#   # plt.xlabel(\"Number of iterations\")\n",
        "#   # plt.ylabel(\"Error\")\n",
        "#   # plt.show()\n",
        "#   print(\"Epoch\",i)\n",
        "#   X_test_norm = Normalise(X_test)\n",
        "#   X_test_norm = X_test_norm.to_numpy()\n",
        "#   X_test_bias = np.delete(X_test_norm,i,1)\n",
        "#   X_test_bias = np.c_[np.ones((357)),X_test_bias]\n",
        "#   pred = np.dot(X_test_bias,batch_w.T)\n",
        "#   print(root_mean_squared_error(pred,y_test))\n",
        "#   pred_train = np.dot(X_new_2,batch_w.T)\n",
        "#   print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVRuIPFkkiXq",
        "outputId": "769a2a0a-68b2-462b-b287-8484e1ae8079"
      },
      "source": [
        "alpha=0.1\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "X_norm_1 = np.delete(X_norm,2,1)\n",
        "for i in range(12):\n",
        "  X_new = X_norm_1\n",
        "  X_new_1 =  np.delete(X_new,i,1)\n",
        "  X_new_2 = np.c_[np.ones((831)),X_new_1]\n",
        "  w = np.zeros((12))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_2,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_norm_1 = np.delete(X_test_norm,2,1)\n",
        "  X_test_bias = np.delete(X_test_norm_1,i,1)\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_bias]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_2,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "360366.77988456265\n",
            "198409.74325891712\n",
            "Epoch 1\n",
            "359031.96843551553\n",
            "198766.77043996722\n",
            "Epoch 2\n",
            "360042.672251137\n",
            "198960.8766096567\n",
            "Epoch 3\n",
            "358719.6789228982\n",
            "198630.086251063\n",
            "Epoch 4\n",
            "361244.4972229721\n",
            "198766.3485295193\n",
            "Epoch 5\n",
            "356955.8264436319\n",
            "207086.97873766618\n",
            "Epoch 6\n",
            "360003.8538626342\n",
            "200390.72629715718\n",
            "Epoch 7\n",
            "364397.66904266446\n",
            "205787.1809928071\n",
            "Epoch 8\n",
            "384059.6721297304\n",
            "205215.1940640041\n",
            "Epoch 9\n",
            "381083.0213839088\n",
            "204943.52743072747\n",
            "Epoch 10\n",
            "357560.86380240513\n",
            "198755.904975213\n",
            "Epoch 11\n",
            "360935.27978942025\n",
            "200047.87050162518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uFrxYH6sKqg"
      },
      "source": [
        "Feature 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWjaMoOeos4V",
        "outputId": "fb79ac9c-c076-461a-b270-e24bfb1d6b64"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "X_norm_1 = np.delete(X_norm,6,1)\n",
        "X_norm_1 = np.delete(X_norm_1,2,1)\n",
        "for i in range(11):\n",
        "  X_new = X_norm_1\n",
        "  X_new_1 =  np.delete(X_new,i,1)\n",
        "  X_new_2 = np.c_[np.ones((831)),X_new_1]\n",
        "  w = np.zeros((11))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_2,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_norm_1 = np.delete(X_test_norm,6,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,2,1)\n",
        "  X_test_bias = np.delete(X_test_norm_1,i,1)\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_bias]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_2,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "359311.80659880885\n",
            "207290.63367820118\n",
            "Epoch 1\n",
            "356472.88106777426\n",
            "207477.90242631227\n",
            "Epoch 2\n",
            "356731.8937404098\n",
            "208466.46127641422\n",
            "Epoch 3\n",
            "356401.4603733461\n",
            "207340.26976419453\n",
            "Epoch 4\n",
            "360631.27115744684\n",
            "209361.62821834531\n",
            "Epoch 5\n",
            "357414.6493330536\n",
            "209621.93896655308\n",
            "Epoch 6\n",
            "361658.51492234255\n",
            "215209.9502163959\n",
            "Epoch 7\n",
            "379955.9460160439\n",
            "213837.58544732278\n",
            "Epoch 8\n",
            "382479.0740259196\n",
            "215852.9557774457\n",
            "Epoch 9\n",
            "354322.8928717752\n",
            "207942.40751357333\n",
            "Epoch 10\n",
            "357470.3092486209\n",
            "209066.24856479742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM9efReCs-7O"
      },
      "source": [
        "Feature 7,12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l7EYxVosvy7",
        "outputId": "0fd2ce85-c824-4dc6-b479-0ae33537fc06"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "X_norm_1 = np.delete(X_norm,11,1)\n",
        "X_norm_1 = np.delete(X_norm_1,6,1)\n",
        "X_norm_1 = np.delete(X_norm_1,2,1)\n",
        "for i in range(10):\n",
        "  X_new = X_norm_1\n",
        "  X_new_1 =  np.delete(X_new,i,1)\n",
        "  X_new_2 = np.c_[np.ones((831)),X_new_1]\n",
        "  w = np.zeros((10))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_2,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_norm_1 = np.delete(X_test_norm,11,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,6,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,2,1)\n",
        "  X_test_bias = np.delete(X_test_norm_1,i,1)\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_bias]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_2,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "356759.5219235291\n",
            "208185.42243036\n",
            "Epoch 1\n",
            "353816.6989772242\n",
            "208344.68088237022\n",
            "Epoch 2\n",
            "353594.9852346561\n",
            "209421.26399326374\n",
            "Epoch 3\n",
            "353984.33068005636\n",
            "208108.30111270837\n",
            "Epoch 4\n",
            "358113.20782445575\n",
            "210052.73494376973\n",
            "Epoch 5\n",
            "355064.1530347328\n",
            "210355.66550365067\n",
            "Epoch 6\n",
            "358026.3734133754\n",
            "218247.25151223273\n",
            "Epoch 7\n",
            "381812.1943236889\n",
            "219235.319612789\n",
            "Epoch 8\n",
            "380402.13121636264\n",
            "218235.58004373166\n",
            "Epoch 9\n",
            "354566.2432149862\n",
            "209850.02927804165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaK7stKStehi"
      },
      "source": [
        "Feature 4,7,12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsY31dYutNoD",
        "outputId": "307cdec4-d45a-4877-8b99-f51131f872a6"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "X_norm_1 = np.delete(X_norm,11,1)\n",
        "X_norm_1 = np.delete(X_norm_1,6,1)\n",
        "X_norm_1 = np.delete(X_norm_1,3,1)\n",
        "X_norm_1 = np.delete(X_norm_1,2,1)\n",
        "for i in range(9):\n",
        "  X_new = X_norm_1\n",
        "  X_new_1 =  np.delete(X_new,i,1)\n",
        "  X_new_2 = np.c_[np.ones((831)),X_new_1]\n",
        "  w = np.zeros((9))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_2,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_norm_1 = np.delete(X_test_norm,11,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,6,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,3,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,2,1)\n",
        "  X_test_bias = np.delete(X_test_norm_1,i,1)\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_bias]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_2,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "355647.003332812\n",
            "209569.0583602173\n",
            "Epoch 1\n",
            "353084.6912720194\n",
            "209848.33745574983\n",
            "Epoch 2\n",
            "353054.6884300014\n",
            "209642.16273306622\n",
            "Epoch 3\n",
            "357368.85983513243\n",
            "211569.74771978508\n",
            "Epoch 4\n",
            "354454.98647740256\n",
            "211744.05186546492\n",
            "Epoch 5\n",
            "358108.29073807\n",
            "219293.18547916188\n",
            "Epoch 6\n",
            "381701.7907839754\n",
            "220254.7796045724\n",
            "Epoch 7\n",
            "379573.3580292795\n",
            "219479.23540306633\n",
            "Epoch 8\n",
            "354509.21591143473\n",
            "209892.13189087156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVq5RQGAt8N-"
      },
      "source": [
        "Feature 4,5,7,12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4URkT-_yttDa",
        "outputId": "bb944ed3-5ade-4e52-c434-b5d6e9f9cd1b"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "X_norm_1 = np.delete(X_norm,11,1)\n",
        "X_norm_1 = np.delete(X_norm_1,6,1)\n",
        "X_norm_1 = np.delete(X_norm_1,4,1)\n",
        "X_norm_1 = np.delete(X_norm_1,3,1)\n",
        "X_norm_1 = np.delete(X_norm_1,2,1)\n",
        "for i in range(8):\n",
        "  X_new = X_norm_1\n",
        "  X_new_1 =  np.delete(X_new,i,1)\n",
        "  X_new_2 = np.c_[np.ones((831)),X_new_1]\n",
        "  w = np.zeros((8))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_2,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_norm_1 = np.delete(X_test_norm,11,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,6,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,4,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,3,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,2,1)\n",
        "  X_test_bias = np.delete(X_test_norm_1,i,1)\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_bias]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_2,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "355204.164206927\n",
            "209805.49918353165\n",
            "Epoch 1\n",
            "352854.96431871684\n",
            "209913.6169308863\n",
            "Epoch 2\n",
            "356993.79842617357\n",
            "211799.21023798262\n",
            "Epoch 3\n",
            "354082.9611078616\n",
            "211814.94903879776\n",
            "Epoch 4\n",
            "357014.7996389014\n",
            "220085.4215270121\n",
            "Epoch 5\n",
            "381529.9582258924\n",
            "220776.2688925338\n",
            "Epoch 6\n",
            "383529.2809333116\n",
            "220306.8140416326\n",
            "Epoch 7\n",
            "353952.63610646024\n",
            "210191.3857038242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s96SVGGP5CQV"
      },
      "source": [
        "Feature 2,4,5,7,12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUY0md0LuLyM",
        "outputId": "71f4d01c-574c-4319-938c-f5c9cb46aba3"
      },
      "source": [
        "alpha=0.01\n",
        "iters=40000\n",
        "X_norm = Normalise(X_train)\n",
        "X_norm = X_norm.to_numpy()\n",
        "X_norm_1 = np.delete(X_norm,11,1)\n",
        "X_norm_1 = np.delete(X_norm_1,6,1)\n",
        "X_norm_1 = np.delete(X_norm_1,4,1)\n",
        "X_norm_1 = np.delete(X_norm_1,3,1)\n",
        "X_norm_1 = np.delete(X_norm_1,2,1)\n",
        "X_norm_1 = np.delete(X_norm_1,1,1)\n",
        "for i in range(7):\n",
        "  X_new = X_norm_1\n",
        "  X_new_1 =  np.delete(X_new,i,1)\n",
        "  X_new_2 = np.c_[np.ones((831)),X_new_1]\n",
        "  w = np.zeros((7))\n",
        "  batch_w, J_his_batch = batch_gradient_descent(X_new_2,y_train,w,alpha,iters)\n",
        "  # plt.plot(range(iters),J_his_batch)\n",
        "  # plt.xlabel(\"Number of iterations\")\n",
        "  # plt.ylabel(\"Error\")\n",
        "  # plt.show()\n",
        "  print(\"Epoch\",i)\n",
        "  X_test_norm = Normalise(X_test)\n",
        "  X_test_norm = X_test_norm.to_numpy()\n",
        "  X_test_norm_1 = np.delete(X_test_norm,11,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,6,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,4,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,3,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,2,1)\n",
        "  X_test_norm_1 = np.delete(X_test_norm_1,1,1)\n",
        "  X_test_bias = np.delete(X_test_norm_1,i,1)\n",
        "  X_test_bias = np.c_[np.ones((357)),X_test_bias]\n",
        "  pred = np.dot(X_test_bias,batch_w.T)\n",
        "  print(root_mean_squared_error(pred,y_test))\n",
        "  pred_train = np.dot(X_new_2,batch_w.T)\n",
        "  print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "355645.50733183575\n",
            "210178.11290643178\n",
            "Epoch 1\n",
            "356989.22763746744\n",
            "212024.8191897232\n",
            "Epoch 2\n",
            "353966.17711285903\n",
            "212101.91922186568\n",
            "Epoch 3\n",
            "357296.119758767\n",
            "220202.0544113436\n",
            "Epoch 4\n",
            "384007.9530762684\n",
            "221288.2950686112\n",
            "Epoch 5\n",
            "384314.0204730676\n",
            "220404.51364091525\n",
            "Epoch 6\n",
            "353762.47283775354\n",
            "210408.56714571844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ7pE_4pvUNx"
      },
      "source": [
        "Finished Backward Greedy Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNlBojzhwH3Q"
      },
      "source": [
        "Simple Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHJdXS2XwHRj",
        "outputId": "48d56f96-b3b2-4935-8106-3af857794a4a"
      },
      "source": [
        "alpha=0.001\n",
        "iters=40000\n",
        "w = np.zeros((14))\n",
        "X_train_bias = np.c_[np.ones((831)),X_rand_train[:,:13]]\n",
        "batch_w, J_his_batch = batch_gradient_descent(X_train_bias,y_train,w,alpha,iters)\n",
        "X_test_bias = np.c_[np.ones((357)),X_rand_test[:,:13]]\n",
        "pred = np.dot(X_test_bias,batch_w.T)\n",
        "pred_train = np.dot(X_train_bias,batch_w.T)\n",
        "print(root_mean_squared_error(pred,y_test))\n",
        "print(root_mean_squared_error(pred_train,y_train))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363500.4747200253\n",
            "199812.44971546254\n"
          ]
        }
      ]
    }
  ]
}